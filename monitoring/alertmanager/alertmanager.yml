# ===========================================================================
# Alertmanager Configuration
# ===========================================================================
#
# This configuration defines how Prometheus alerts are routed to notification
# channels. Alerts flow: Prometheus ‚Üí Alertmanager ‚Üí Notification Receivers
#
# Severity Levels:
#   - critical: Immediate attention required (system-wide impact)
#   - high: Urgent attention required (service degradation)
#   - warning: Attention recommended (potential issues)
#
# Documentation: docs/operators/alerting-setup-guide.md
# ===========================================================================

# ===========================================================================
# Global Settings
# ===========================================================================
global:
  # Time before alert auto-resolves if no longer firing
  resolve_timeout: 5m

  # SMTP Configuration (Optional - Uncomment to enable email notifications)
  # smtp_smarthost: 'smtp.example.com:587'
  # smtp_from: 'alertmanager@example.com'
  # smtp_auth_username: 'alertmanager'
  # smtp_auth_password: 'your-smtp-password'
  # smtp_require_tls: true

  # Slack API URL (Optional - Can be set here or in receiver configuration)
  # slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

# ===========================================================================
# Alert Routing Configuration
# ===========================================================================
route:
  # Group alerts by alertname and severity for efficient batching
  group_by: ['alertname', 'severity']

  # Wait 30s before sending first notification for new alert group
  # Allows related alerts to batch together
  group_wait: 30s

  # Wait 5m before sending batch of new alerts in existing group
  group_interval: 5m

  # Resend unresolved alert notifications every 4h
  repeat_interval: 4h

  # Default receiver for alerts without specific route
  receiver: 'default'

  # Severity-based routing rules
  routes:
    # Critical alerts ‚Üí immediate notification (PagerDuty, etc.)
    - match:
        severity: critical
      receiver: 'critical-alerts'
      # Override repeat_interval for critical alerts (send every 1h)
      repeat_interval: 1h

    # High severity alerts ‚Üí urgent notification (Slack, etc.)
    - match:
        severity: high
      receiver: 'high-alerts'

# ===========================================================================
# Notification Receivers
# ===========================================================================
receivers:
  # ---------------------------------------------------------------------------
  # Default Receiver - Warning and unmatched alerts
  # ---------------------------------------------------------------------------
  - name: 'default'
    # Configure one or more notification channels below (uncomment to enable)

    # Webhook Example:
    # webhook_configs:
    #   - url: 'http://your-webhook-endpoint/alerts'
    #     send_resolved: true

    # Email Example:
    # email_configs:
    #   - to: 'ops-team@example.com'
    #     subject: 'ILP Connector Alert: {{ .GroupLabels.alertname }}'
    #     html: |
    #       <h2>{{ .GroupLabels.alertname }}</h2>
    #       <p><strong>Severity:</strong> {{ .GroupLabels.severity }}</p>
    #       <p><strong>Summary:</strong> {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}</p>
    #       <p><strong>Description:</strong> {{ range .Alerts }}{{ .Annotations.description }}{{ end }}</p>

    # Slack Example:
    # slack_configs:
    #   - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
    #     channel: '#ilp-alerts'
    #     title: 'ILP Connector Alert: {{ .GroupLabels.alertname }}'
    #     text: |
    #       *Severity:* {{ .GroupLabels.severity }}
    #       *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
    #       *Runbook:* {{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}
    #     color: 'warning'

  # ---------------------------------------------------------------------------
  # Critical Alerts Receiver - Immediate response required
  # ---------------------------------------------------------------------------
  - name: 'critical-alerts'
    # PagerDuty configuration for on-call escalation

    # PagerDuty Example (Events API v2):
    # pagerduty_configs:
    #   - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
    #     description: '{{ .GroupLabels.alertname }}: {{ .GroupLabels.instance }}'
    #     details:
    #       severity: '{{ .GroupLabels.severity }}'
    #       summary: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
    #       runbook_url: '{{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}'

    # Slack Critical Channel Example:
    # slack_configs:
    #   - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
    #     channel: '#ilp-critical-alerts'
    #     title: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
    #     text: |
    #       *Instance:* {{ .GroupLabels.instance }}
    #       *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
    #       *Description:* {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
    #       *Runbook:* {{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}
    #     color: 'danger'

    # Email + SMS Gateway Example (critical escalation):
    # email_configs:
    #   - to: 'oncall@example.com,+1234567890@sms.example.com'
    #     subject: 'üö® CRITICAL ALERT: {{ .GroupLabels.alertname }}'

  # ---------------------------------------------------------------------------
  # High Severity Alerts Receiver - Urgent notification
  # ---------------------------------------------------------------------------
  - name: 'high-alerts'
    # Slack channel for high-priority alerts

    # Slack Example:
    # slack_configs:
    #   - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
    #     channel: '#ilp-alerts'
    #     title: '‚ö†Ô∏è HIGH: {{ .GroupLabels.alertname }}'
    #     text: |
    #       *Instance:* {{ .GroupLabels.instance }}
    #       *Summary:* {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
    #       *Description:* {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
    #       *Runbook:* {{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}
    #     color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'

    # Email Example:
    # email_configs:
    #   - to: 'ops-team@example.com'
    #     subject: '‚ö†Ô∏è HIGH ALERT: {{ .GroupLabels.alertname }}'

    # Webhook Example (custom integration):
    # webhook_configs:
    #   - url: 'http://your-monitoring-system/high-alerts'
    #     send_resolved: true

# ===========================================================================
# Inhibition Rules
# ===========================================================================
# Suppress lower-severity alerts when higher-severity alert active
inhibit_rules:
  # Suppress warning alerts when critical alert firing for same alertname
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname']

  # Suppress warning alerts when high alert firing for same alertname
  - source_match:
      severity: 'high'
    target_match:
      severity: 'warning'
    equal: ['alertname']

  # Example: Suppress HighMemoryUsage when ConnectorDown firing
  # - source_match:
  #     alertname: 'ConnectorDown'
  #   target_match:
  #     alertname: 'HighMemoryUsage'
  #   equal: ['instance']
