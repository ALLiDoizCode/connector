<!-- Powered by BMAD™ Core -->

# Story 2.4: Create Dockerfile for Connector Application

## Status

Done

## Story

**As a** DevOps engineer,
**I want** a Dockerfile that builds and packages the connector application,
**so that** I can deploy connector nodes as containers.

## Acceptance Criteria

1. `Dockerfile` created in repository root using `node:20-alpine` base image
2. Dockerfile uses multi-stage build (builder stage compiles TypeScript, runtime stage runs compiled JavaScript)
3. Dockerfile copies only necessary files to runtime stage (dist, node_modules production deps, package.json)
4. Dockerfile exposes BTP server port (3000) for incoming connections
5. Dockerfile sets appropriate working directory and non-root user for security
6. Dockerfile includes HEALTHCHECK instruction that verifies connector process is running
7. Docker image builds successfully with `docker build -t ilp-connector .`
8. Docker image size optimized (<200MB for Alpine-based image)
9. Container starts successfully and logs appear via `docker logs`
10. Environment variables can be passed to container to configure BTP ports, peer connections, and log level

## Tasks / Subtasks

**Task Execution Strategy:** Task 1 creates the multi-stage Dockerfile with build and runtime stages. Task 2 adds a start script for the connector. Task 3 implements security hardening with non-root user. Task 4 adds health check functionality. Task 5 optimizes image size. Task 6 creates comprehensive documentation. Task 7 validates the Dockerfile with build and run tests.

**Important:** Tasks 1 and 2 can be developed in parallel, but the Docker image cannot be successfully built until both are complete. Task 1 defines the Dockerfile structure, and Task 2 creates the entry point source code that Task 1's build process will compile.

- [ ] Task 1: Create Multi-Stage Dockerfile (AC: 1, 2, 3)
  - [ ] Create `Dockerfile` in repository root
  - [ ] Define builder stage using `node:20-alpine` as base image
  - [ ] Set working directory to `/app` in builder stage
  - [ ] Copy root `package.json` and `package-lock.json` to `/app/` (for workspace definition)
  - [ ] Copy all workspace package.json files: `packages/*/package.json` to preserve structure
  - [ ] Run `npm ci --workspaces` to install all dependencies (including devDependencies for build)
  - [ ] Copy all source files: `packages/`, `tsconfig.base.json`, `.eslintrc.json` to `/app/`
  - [ ] Run TypeScript build for all packages: `npm run build --workspaces`
  - [ ] Define runtime stage using `node:20-alpine` as fresh base image
  - [ ] Set working directory to `/app` in runtime stage
  - [ ] Copy `package.json` and `package-lock.json` from builder stage
  - [ ] Copy all workspace package.json files from builder stage to preserve structure
  - [ ] Run `npm ci --workspaces --omit=dev` to install only production dependencies
  - [ ] Copy compiled output from builder stage: `/app/packages/connector/dist` to `/app/packages/connector/dist`
  - [ ] Copy compiled output from builder stage: `/app/packages/shared/dist` to `/app/packages/shared/dist`
  - [ ] Verify only production artifacts copied (no `src/`, `test/`, or `node_modules/dev-deps`)
  - [ ] [Source: architecture/infrastructure-and-deployment.md#deployment-strategy, architecture/tech-stack.md#container-base-image]

- [ ] Task 2: Create Connector Entry Point Script (AC: 9, 10)
  - [ ] Create `packages/connector/src/index.ts` as main entry point
  - [ ] Import ConnectorNode from `./core/connector-node`
  - [ ] Import logger from `./utils/logger`
  - [ ] Read configuration from environment variables:
    - [ ] `NODE_ID`: Connector identifier (default: 'connector-node')
    - [ ] `BTP_SERVER_PORT`: BTP server listening port (default: 3000)
    - [ ] `LOG_LEVEL`: Pino log level (default: 'info')
  - [ ] Create ConnectorConfig object from environment variables (inline config for now, YAML loading in Story 2.6)
  - [ ] Instantiate ConnectorNode with config and logger
  - [ ] Call `connectorNode.start()` to initialize connector
  - [ ] Log startup message at INFO level: { event: 'connector_started', nodeId, btpServerPort }
  - [ ] Handle process signals for graceful shutdown:
    - [ ] Listen for SIGTERM and SIGINT signals
    - [ ] Call `connectorNode.stop()` on signal received
    - [ ] Log shutdown message: { event: 'connector_shutdown', nodeId }
    - [ ] Exit process with code 0 after cleanup
  - [ ] Handle uncaught errors:
    - [ ] Listen for 'uncaughtException' and 'unhandledRejection' events
    - [ ] Log error at ERROR level with full stack trace
    - [ ] Call `connectorNode.stop()` for cleanup
    - [ ] Exit process with code 1
  - [ ] Update `packages/connector/package.json` to add `start` script: `"start": "node dist/index.js"`
  - [ ] [Source: architecture/source-tree.md#connector-entry-point, architecture/coding-standards.md#critical-rules]

- [ ] Task 3: Configure Security Hardening (AC: 5)
  - [ ] Add `USER` instruction to Dockerfile before CMD to run as non-root
  - [ ] Create system user `node` in runtime stage (Alpine image includes this by default)
  - [ ] Change ownership of application files to `node:node` user
  - [ ] Use `USER node` directive to switch from root to node user
  - [ ] Verify node user has read access to `/app` directory and execute permission on entrypoint
  - [ ] Verify node user does NOT have write access to application code (security best practice)
  - [ ] Set `NODE_ENV=production` environment variable in runtime stage
  - [ ] Document security rationale in Dockerfile comments: non-root user prevents privilege escalation
  - [ ] [Source: architecture/security.md#api-security, architecture/infrastructure-and-deployment.md#deployment-strategy]

- [ ] Task 4: Add Docker Health Check (AC: 6)
  - [ ] Add HEALTHCHECK instruction to Dockerfile
  - [ ] Health check command: `CMD node -e "require('http').get('http://localhost:8080/health', (res) => { process.exit(res.statusCode === 200 ? 0 : 1); }).on('error', () => { process.exit(1); });"`
  - [ ] Note: This health check assumes Story 2.7 will implement HTTP health endpoint at `/health` on port 8080
  - [ ] For now, use simplified check that verifies node process is running: `CMD ps aux | grep -F 'node packages/connector/dist/index.js' || exit 1`
  - [ ] Set health check interval to 30s (avoid excessive checks)
  - [ ] Set health check timeout to 10s
  - [ ] Set health check start period to 10s (allow time for connector startup)
  - [ ] Set health check retries to 3 (mark unhealthy after 3 consecutive failures)
  - [ ] Document in Dockerfile comments that full health check requires Story 2.7 implementation
  - [ ] [Source: architecture/infrastructure-and-deployment.md#deployment-strategy]

- [ ] Task 5: Optimize Image Size (AC: 8)
  - [ ] Add `.dockerignore` file in repository root to exclude unnecessary files from build context
  - [ ] Exclude from Docker context: `node_modules`, `dist`, `.git`, `*.test.ts`, `*.test.js`, `.env`, `*.md` (except README)
  - [ ] Exclude development files: `jest.config.js`, `.eslintrc.json`, `.prettierrc.json`, `tsconfig.*.json`
  - [ ] Verify multi-stage build only copies production dependencies (no devDependencies in runtime)
  - [ ] Use `npm ci` instead of `npm install` for reproducible builds
  - [ ] Use `--omit=dev` flag in runtime stage to exclude devDependencies
  - [ ] Build image and verify size: `docker build -t ilp-connector . && docker images ilp-connector`
  - [ ] Target image size: <200MB (Alpine base ~150MB + Node.js dependencies ~30-40MB)
  - [ ] If image exceeds 200MB, investigate with `docker history ilp-connector` to identify large layers
  - [ ] Document image size optimization techniques in Dockerfile comments
  - [ ] [Source: architecture/tech-stack.md#container-base-image, architecture/infrastructure-and-deployment.md#deployment-strategy]

- [ ] Task 6: Add Dockerfile Documentation and Usage Instructions (AC: 7, 9, 10)
  - [ ] Add comprehensive header comments to Dockerfile explaining purpose and build stages
  - [ ] Document each stage (builder, runtime) with inline comments
  - [ ] Document all exposed ports with comments explaining their purpose
  - [ ] Document required environment variables with examples in comments
  - [ ] Create `README.md` section: "Running with Docker"
    - [ ] Document build command: `docker build -t ilp-connector .`
    - [ ] Document run command with environment variables: `docker run -e NODE_ID=connector-a -e BTP_SERVER_PORT=3000 -p 3000:3000 ilp-connector`
    - [ ] Document log viewing: `docker logs <container-id>`
    - [ ] Document container shell access for debugging: `docker exec -it <container-id> sh`
    - [ ] List all configurable environment variables with defaults
  - [ ] Add troubleshooting section for common Docker issues (port conflicts, permission errors)
  - [ ] [Source: architecture/infrastructure-and-deployment.md#deployment-flow]

- [ ] Task 7: Create Docker Build and Run Validation Tests (AC: 7, 9)
  - [ ] Create shell script `scripts/test-docker-build.sh` for automated testing
  - [ ] Script step 1: Build Docker image: `docker build -t ilp-connector-test .`
  - [ ] Script step 2: Verify build succeeded with exit code 0
  - [ ] Script step 3: Check image size is <200MB: `docker images ilp-connector-test --format "{{.Size}}"`
  - [ ] Script step 4: Start container with test configuration: `docker run -d -e NODE_ID=test-node -e BTP_SERVER_PORT=3001 -p 3001:3001 --name ilp-connector-test-run ilp-connector-test`
  - [ ] Script step 5: Wait 5 seconds for container startup
  - [ ] Script step 6: Verify container is running: `docker ps | grep ilp-connector-test-run`
  - [ ] Script step 7: Capture container logs: `docker logs ilp-connector-test-run`
  - [ ] Script step 8: Verify logs contain startup message with event: 'connector_started'
  - [ ] Script step 9: Clean up test container: `docker stop ilp-connector-test-run && docker rm ilp-connector-test-run`
  - [ ] Script step 10: Clean up test image: `docker rmi ilp-connector-test`
  - [ ] Make script executable: `chmod +x scripts/test-docker-build.sh`
  - [ ] Document test script in README.md under "Testing" section
  - [ ] Run script manually to verify all checks pass
  - [ ] [Source: architecture/test-strategy-and-standards.md#continuous-testing]

- [ ] Task 8: Create Integration Test for Dockerized Connector (AC: 9, 10)
  - [ ] Create `packages/connector/test/integration/docker-container.test.ts`
  - [ ] Test requires Docker installed and Docker daemon running
  - [ ] Use Jest with longer timeout (30s) for Docker operations: `jest.setTimeout(30000)`
  - [ ] Test 1: Verify Docker image builds successfully
    - [ ] Arrange: Ensure no existing test image
    - [ ] Act: Execute `docker build -t ilp-connector-integration-test .` using child_process.exec
    - [ ] Assert: Build command exits with code 0
    - [ ] Assert: Image exists in `docker images` output
  - [ ] Test 2: Verify container starts and logs appear
    - [ ] Arrange: Build test image
    - [ ] Act: Start container with `docker run -d -e NODE_ID=integration-test --name ilp-test-container ilp-connector-integration-test`
    - [ ] Wait 3 seconds for startup
    - [ ] Act: Capture logs with `docker logs ilp-test-container`
    - [ ] Assert: Logs contain "connector_started" event
    - [ ] Assert: Logs contain nodeId: "integration-test"
    - [ ] Cleanup: Stop and remove container
  - [ ] Test 3: Verify environment variables configure connector
    - [ ] Arrange: Build test image
    - [ ] Act: Start container with custom environment: `-e NODE_ID=custom-node -e BTP_SERVER_PORT=4000 -e LOG_LEVEL=debug`
    - [ ] Act: Capture logs
    - [ ] Assert: Logs show nodeId: "custom-node"
    - [ ] Assert: Logs show btpServerPort: 4000
    - [ ] Assert: Log level is DEBUG (verified by presence of debug-level logs)
    - [ ] Cleanup: Stop and remove container
  - [ ] Test 4: Verify graceful shutdown on SIGTERM
    - [ ] Arrange: Start container
    - [ ] Act: Send SIGTERM signal: `docker stop ilp-test-container` (sends SIGTERM)
    - [ ] Wait for container to exit (max 10s)
    - [ ] Act: Capture logs
    - [ ] Assert: Logs contain "connector_shutdown" event
    - [ ] Assert: Container exited with code 0
    - [ ] Cleanup: Remove container
  - [ ] Add cleanup in afterEach hook to remove test containers and images
  - [ ] Mark test as skipped if Docker is not available: `test.skipIf(!isDockerAvailable())`
  - [ ] [Source: architecture/test-strategy-and-standards.md#integration-tests]

## Dev Notes

### Previous Story Insights

**From Story 2.3 (Integrate BTP with Packet Forwarding):**
[Source: docs/stories/2.3.story.md#dev-agent-record]

- ConnectorNode class fully implemented in `packages/connector/src/core/connector-node.ts`
- ConnectorNode orchestrates all components: RoutingTable, BTPClientManager, PacketHandler, BTPServer
- ConnectorNode.start() method initializes BTP server and connects all BTP clients
- ConnectorNode.stop() method provides graceful shutdown of all components
- ConnectorConfig interface defined with: nodeId, btpServerPort, peers, routes
- All tests passing: 198 passing, 2 skipped, 21 failing (89.6% pass rate)
- **Critical takeaway:** Connector entry point needs to instantiate ConnectorNode and handle lifecycle

**From Story 1.6 (Integrate Pino Structured Logging):**
[Source: docs/stories/1.6.story.md]

- Logger configured in `packages/connector/src/utils/logger.ts` with Pino 8.17.x
- Logger supports LOG_LEVEL environment variable for runtime configuration
- Structured logging includes nodeId, component, correlationId fields
- **Important:** Entry point must configure logger with nodeId from environment

### Technical Context

**Dockerfile Multi-Stage Build Pattern:**
[Source: architecture/infrastructure-and-deployment.md#deployment-strategy]

Multi-stage builds separate build-time dependencies from runtime, reducing final image size significantly.

**Pattern Structure:**

```dockerfile
# Stage 1: Builder - Contains TypeScript compiler and devDependencies
FROM node:20-alpine AS builder
WORKDIR /app
COPY package*.json ./
COPY packages/*/package.json ./packages/
RUN npm ci --workspaces
COPY . .
RUN npm run build --workspaces

# Stage 2: Runtime - Contains only production dependencies and compiled JavaScript
FROM node:20-alpine AS runtime
WORKDIR /app
COPY package*.json ./
COPY packages/*/package.json ./packages/
RUN npm ci --workspaces --omit=dev
COPY --from=builder /app/packages/connector/dist ./packages/connector/dist
COPY --from=builder /app/packages/shared/dist ./packages/shared/dist
```

**Container Base Image:**
[Source: architecture/tech-stack.md#technology-stack-table]

- **Image:** `node:20-alpine`
- **Version:** Node.js 20.11.0 LTS on Alpine Linux
- **Size:** ~150MB base (vs. ~900MB for standard node:20)
- **Rationale:** Small footprint, official Node.js image, Alpine Linux security benefits, faster startup
- **Security:** Alpine uses musl libc (smaller attack surface than glibc)

**Environment Variable Configuration:**
[Source: architecture/tech-stack.md#configuration-format, architecture/coding-standards.md#critical-rules]

Connector must support configuration via environment variables for Docker Compose compatibility:

- `NODE_ID`: Unique connector identifier (required)
- `BTP_SERVER_PORT`: Port for incoming BTP connections (default: 3000)
- `LOG_LEVEL`: Pino log level (default: 'info', options: 'debug', 'info', 'warn', 'error')
- Future (Story 2.6): `CONFIG_FILE`: Path to YAML topology configuration file

**Security Best Practices:**
[Source: architecture/security.md#secrets-management]

- **Non-root user:** Run container as `node` user (UID 1000) to prevent privilege escalation
- **No secrets in image:** All secrets passed via environment variables at runtime
- **Read-only application:** Application code should be immutable in container
- **Minimal attack surface:** Only install production dependencies in runtime stage

### File Locations and Project Structure

**New Files to Create:**

- `Dockerfile` - Multi-stage Docker build configuration (repository root)
- `.dockerignore` - Exclude files from Docker build context (repository root)
- `packages/connector/src/index.ts` - Connector entry point script
- `scripts/test-docker-build.sh` - Docker build validation script
- `packages/connector/test/integration/docker-container.test.ts` - Docker integration tests

**Existing Files to Modify:**

- `packages/connector/package.json` - Add `start` script for production runtime
- `README.md` - Add Docker usage documentation

**Project Structure After This Story:**
[Source: architecture/source-tree.md]

```
m2m/                                  # Monorepo root
├── Dockerfile                        # NEW - Multi-stage connector build
├── .dockerignore                     # NEW - Build context exclusions
├── scripts/
│   └── test-docker-build.sh          # NEW - Docker validation script
├── packages/
│   ├── connector/
│   │   ├── src/
│   │   │   ├── index.ts              # NEW - Entry point
│   │   │   ├── core/
│   │   │   │   └── connector-node.ts # Existing - Orchestrator
│   │   │   ├── btp/                  # Existing - BTP components
│   │   │   └── utils/
│   │   │       └── logger.ts         # Existing - Pino config
│   │   ├── test/
│   │   │   └── integration/
│   │   │       └── docker-container.test.ts  # NEW - Docker tests
│   │   └── package.json              # MODIFY - Add start script
│   └── shared/                       # Existing - Shared types
└── README.md                         # MODIFY - Add Docker docs
```

### Data Models Relevant to This Story

**ConnectorConfig (Environment-based):**
[Source: architecture/data-models.md#connectorconfig]

For this story, configuration will be sourced from environment variables (YAML loading in Story 2.6):

```typescript
interface ConnectorConfig {
  nodeId: string; // From NODE_ID env var
  btpServerPort: number; // From BTP_SERVER_PORT env var (default: 3000)
  peers: Peer[]; // Empty array for now (Story 2.6 loads from YAML)
  routes: RoutingTableEntry[]; // Empty array for now (Story 2.6 loads from YAML)
}
```

**Entry Point Implementation:**

```typescript
// packages/connector/src/index.ts
import { ConnectorNode } from './core/connector-node';
import { createLogger } from './utils/logger';

const nodeId = process.env.NODE_ID || 'connector-node';
const btpServerPort = parseInt(process.env.BTP_SERVER_PORT || '3000', 10);
const logLevel = process.env.LOG_LEVEL || 'info';

const logger = createLogger({ level: logLevel, nodeId });

const config = {
  nodeId,
  btpServerPort,
  peers: [], // Will be loaded from YAML in Story 2.6
  routes: [], // Will be loaded from YAML in Story 2.6
};

const connectorNode = new ConnectorNode(config, logger);

async function start() {
  try {
    await connectorNode.start();
    logger.info({ event: 'connector_started', nodeId, btpServerPort });
  } catch (error) {
    logger.error({ event: 'connector_start_failed', error: error.message });
    process.exit(1);
  }
}

async function shutdown(signal: string) {
  logger.info({ event: 'connector_shutdown_initiated', signal });
  try {
    await connectorNode.stop();
    logger.info({ event: 'connector_shutdown', nodeId });
    process.exit(0);
  } catch (error) {
    logger.error({ event: 'connector_shutdown_failed', error: error.message });
    process.exit(1);
  }
}

process.on('SIGTERM', () => shutdown('SIGTERM'));
process.on('SIGINT', () => shutdown('SIGINT'));
process.on('uncaughtException', (error) => {
  logger.error({ event: 'uncaught_exception', error: error.message, stack: error.stack });
  shutdown('uncaughtException');
});
process.on('unhandledRejection', (reason) => {
  logger.error({ event: 'unhandled_rejection', reason });
  shutdown('unhandledRejection');
});

start();
```

### Dockerfile Implementation Details

**Complete Dockerfile Example:**

```dockerfile
# Multi-stage Dockerfile for ILP Connector
# Stage 1: Build - Compiles TypeScript to JavaScript
# Stage 2: Runtime - Runs compiled connector with production dependencies only

# ============================================
# Stage 1: Builder
# ============================================
FROM node:20-alpine AS builder

# Set working directory
WORKDIR /app

# Copy dependency manifests first (for layer caching)
COPY package*.json ./
COPY tsconfig.base.json ./
COPY packages/connector/package.json ./packages/connector/
COPY packages/shared/package.json ./packages/shared/

# Install all dependencies (including devDependencies for build)
RUN npm ci --workspaces

# Copy source code
COPY packages/ ./packages/

# Build all packages (TypeScript compilation)
RUN npm run build --workspaces

# ============================================
# Stage 2: Runtime
# ============================================
FROM node:20-alpine AS runtime

# Set production environment
ENV NODE_ENV=production

# Set working directory
WORKDIR /app

# Copy dependency manifests
COPY package*.json ./
COPY packages/connector/package.json ./packages/connector/
COPY packages/shared/package.json ./packages/shared/

# Install production dependencies only
RUN npm ci --workspaces --omit=dev

# Copy compiled JavaScript from builder stage
COPY --from=builder /app/packages/connector/dist ./packages/connector/dist
COPY --from=builder /app/packages/shared/dist ./packages/shared/dist

# Create non-root user (node user already exists in Alpine)
# Change ownership of application files
RUN chown -R node:node /app

# Switch to non-root user
USER node

# Expose BTP server port (configurable via BTP_SERVER_PORT env var)
EXPOSE 3000

# Health check (verifies node process is running)
# Note: Full health check endpoint will be added in Story 2.7
HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \
  CMD ps aux | grep -F 'node packages/connector/dist/index.js' || exit 1

# Start connector
CMD ["node", "packages/connector/dist/index.js"]
```

**.dockerignore Example:**

```
# Dependencies
node_modules/

# Build output
dist/
*.tsbuildinfo

# Tests
*.test.ts
*.test.js
test/
coverage/

# Development files
.git/
.github/
.vscode/
*.md
!README.md

# Configuration
.env
.env.*
jest.config.js
tsconfig.*.json
.eslintrc.json
.prettierrc.json

# Logs
*.log
npm-debug.log*

# OS files
.DS_Store
Thumbs.db
```

### Testing Strategy for This Story

**Docker Build Validation Script:**
[Source: architecture/test-strategy-and-standards.md#continuous-testing]

Create automated shell script to verify Docker build and runtime:

```bash
#!/bin/bash
# scripts/test-docker-build.sh
# Validates Docker image builds correctly and container starts successfully

set -e  # Exit on error

echo "=== Testing Docker Build ==="

# Clean up any existing test resources
docker rm -f ilp-connector-test-run 2>/dev/null || true
docker rmi ilp-connector-test 2>/dev/null || true

# Build Docker image
echo "Building Docker image..."
docker build -t ilp-connector-test .

# Check image size
IMAGE_SIZE=$(docker images ilp-connector-test --format "{{.Size}}")
echo "Image size: $IMAGE_SIZE"

# Start container
echo "Starting test container..."
docker run -d \
  -e NODE_ID=test-node \
  -e BTP_SERVER_PORT=3001 \
  -p 3001:3001 \
  --name ilp-connector-test-run \
  ilp-connector-test

# Wait for startup
echo "Waiting for container startup..."
sleep 5

# Verify container is running
if docker ps | grep -q ilp-connector-test-run; then
  echo "✓ Container is running"
else
  echo "✗ Container failed to start"
  exit 1
fi

# Check logs
echo "Checking container logs..."
docker logs ilp-connector-test-run

LOGS=$(docker logs ilp-connector-test-run 2>&1)
if echo "$LOGS" | grep -q "connector_started"; then
  echo "✓ Startup log found"
else
  echo "✗ Startup log not found"
  exit 1
fi

# Clean up
echo "Cleaning up test resources..."
docker stop ilp-connector-test-run
docker rm ilp-connector-test-run
docker rmi ilp-connector-test

echo "=== Docker Build Test Passed ==="
```

**Integration Test Coverage:**

- Docker image builds without errors
- Container starts and runs successfully
- Environment variables configure connector correctly
- Graceful shutdown handles SIGTERM/SIGINT signals
- Logs are accessible via `docker logs`

### Definition of Done Checklist

- [ ] Dockerfile created in repository root with multi-stage build (builder + runtime)
- [ ] Dockerfile uses `node:20-alpine` base image for both stages
- [ ] Builder stage installs all dependencies and compiles TypeScript
- [ ] Runtime stage installs only production dependencies
- [ ] Runtime stage copies only compiled JavaScript (dist/) from builder
- [ ] .dockerignore file excludes unnecessary files from build context
- [ ] Dockerfile exposes port 3000 for BTP server
- [ ] Dockerfile runs as non-root `node` user
- [ ] Dockerfile includes HEALTHCHECK instruction
- [ ] Dockerfile sets NODE_ENV=production in runtime stage
- [ ] Entry point script created: `packages/connector/src/index.ts`
- [ ] Entry point reads NODE_ID, BTP_SERVER_PORT, LOG_LEVEL from environment
- [ ] Entry point instantiates ConnectorNode and calls start()
- [ ] Entry point handles SIGTERM/SIGINT for graceful shutdown
- [ ] Entry point handles uncaught exceptions and unhandled rejections
- [ ] packages/connector/package.json includes `start` script
- [ ] Docker image builds successfully: `docker build -t ilp-connector .`
- [ ] Docker image size is <200MB (verified with `docker images`)
- [ ] Container starts successfully with default configuration
- [ ] Container logs appear via `docker logs <container-id>`
- [ ] Environment variables configure connector at runtime
- [ ] Documentation added to README.md: "Running with Docker" section
- [ ] Dockerfile includes comprehensive comments explaining each stage
- [ ] Shell script created: `scripts/test-docker-build.sh` for build validation
- [ ] Shell script verifies build, run, logs, and cleanup
- [ ] Integration test created: `docker-container.test.ts` for automated validation
- [ ] All tests pass: `npm test --workspace=packages/connector`
- [ ] TypeScript compiles: `npm run build --workspace=packages/connector`

## Testing

### Test Execution Commands

**Build Docker Image:**

```bash
docker build -t ilp-connector .
```

**Run Container with Default Config:**

```bash
docker run -d -e NODE_ID=connector-a -e BTP_SERVER_PORT=3000 -p 3000:3000 --name connector-a ilp-connector
```

**View Container Logs:**

```bash
docker logs connector-a
```

**Run Build Validation Script:**

```bash
./scripts/test-docker-build.sh
```

**Run Docker Integration Tests:**

```bash
npm test --workspace=packages/connector -- docker-container.test.ts
```

**Check Image Size:**

```bash
docker images ilp-connector
```

**Inspect Image Layers:**

```bash
docker history ilp-connector
```

**Access Container Shell (Debugging):**

```bash
docker exec -it connector-a sh
```

**Stop and Remove Container:**

```bash
docker stop connector-a && docker rm connector-a
```

### Expected Test Results

**Before Story Completion:**

- No Dockerfile exists
- No Docker image for connector
- Connector only runnable via `npm run dev`

**After Story Completion:**

- Docker image builds in <2 minutes
- Image size: 150-200MB (Alpine base + Node.js dependencies)
- Container starts in <5 seconds
- Logs show structured JSON output from Pino
- Startup log contains: `{ "event": "connector_started", "nodeId": "...", "btpServerPort": 3000 }`
- Container health check passes after startup period
- Environment variables successfully configure NODE_ID, BTP_SERVER_PORT, LOG_LEVEL
- Graceful shutdown completes in <2 seconds on SIGTERM

### Manual Testing Scenarios

**Scenario 1: Build and Run with Default Configuration**

```bash
# Build image
docker build -t ilp-connector .

# Verify build succeeded
echo $?  # Should output: 0

# Check image size
docker images ilp-connector

# Run container
docker run -d -e NODE_ID=test-connector -p 3000:3000 --name test-connector ilp-connector

# Verify container is running
docker ps | grep test-connector

# Check logs
docker logs test-connector
# Expected: JSON log entries with "connector_started" event

# Clean up
docker stop test-connector && docker rm test-connector
```

**Scenario 2: Test Environment Variable Configuration**

```bash
# Run with custom configuration
docker run -d \
  -e NODE_ID=custom-node \
  -e BTP_SERVER_PORT=4000 \
  -e LOG_LEVEL=debug \
  -p 4000:4000 \
  --name custom-connector \
  ilp-connector

# Verify custom config in logs
docker logs custom-connector | grep "custom-node"
docker logs custom-connector | grep "4000"
docker logs custom-connector | grep "debug"

# Clean up
docker stop custom-connector && docker rm custom-connector
```

**Scenario 3: Test Graceful Shutdown**

```bash
# Start container
docker run -d -e NODE_ID=shutdown-test --name shutdown-test ilp-connector

# Send SIGTERM (via docker stop)
docker stop shutdown-test

# Verify shutdown log appears
docker logs shutdown-test | grep "connector_shutdown"

# Clean up
docker rm shutdown-test
```

**Scenario 4: Verify Image Size Optimization**

```bash
# Build image
docker build -t ilp-connector .

# Check image size
docker images ilp-connector --format "{{.Size}}"
# Expected: <200MB

# Inspect image layers to identify large layers
docker history ilp-connector

# Verify only production dependencies in image
docker run --rm ilp-connector sh -c "ls -la /app/packages/connector/"
# Expected: dist/ directory present, src/ absent
```

## Dev Agent Record

### Agent Model Used

- TBD

### Debug Log References

- TBD

### Completion Notes

- TBD

### File List

**New Files:**

- TBD

**Modified Files:**

- TBD

## QA Review Summary

**Review Date:** TBD
**Reviewer:** TBD
**Status:** TBD

## Change Log

| Date       | Version | Description                                                    | Author     |
| ---------- | ------- | -------------------------------------------------------------- | ---------- |
| 2025-12-27 | 1.1     | Fixed health check grep pattern and added task dependency note | BMAD Agent |
| 2025-12-27 | 1.0     | Initial story draft                                            | BMAD Agent |
